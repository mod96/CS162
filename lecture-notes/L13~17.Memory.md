- Page Table

# 1. Address Translation

<p align="center">
    <img src="imgs/14_6.PNG" width="60%" />
</p>

## 1.1. Important Aspects

- Protection:
  - Prevent access to private memory of other processes
    - Different pages of memory can be given special behavior (Read Only, Invisible to user programs, etc).
    - Kernel data protected from User programs
    - Programs protected from themselves
- Translation:
  - Ability to translate accesses from one address space (virtual) to a different one
(physical)
  - When translation exists, processor uses virtual addresses, physical memory
uses physical addresses
  - Side effects:
    - Can be used to avoid overlap
    - Can be used to give uniform view of memory to programs
- Controlled overlap:
  - Separate state of threads should not collide in physical memory. Obviously, unexpected overlap causes chaos!
  - Conversely, would like the ability to overlap when desired (for communication)

\*  Can we protect programs from each other without translation? 

=> Yes: Base and Bound!

## 1.2. Base and Bound (B&B)

### 1.2.1. B&B (No Translation)

This needs to load program with address changed.

<p align="center">
    <img src="imgs/13_1.PNG" width="60%" />
</p>


### 1.2.2. B&B (With Translation)

From now, MMU (Memory Management Unit) involves.

<p align="center">
    <img src="imgs/13_2.PNG" width="60%" />
</p>

But these problems remain:

- Fragmentation problem over time
  - Not every process is same size => memory becomes fragmented over time
- Missing support for sparse address space
  - Would like to have multiple chunks/program (Code, Data, Stack, Heap, etc)
- Hard to do inter-process sharing
  - Want to share code segments when possible
  - Want to share memory between processes
  - Helped by providing multiple segments per process

### 1.2.3. Segmentation (B&B, Translation, Multi-Segment)

Each segment is given region of contiguous memory. These have base and limit. Segment table is in CPU (MMU). And different for each process.

<p align="center">
    <img src="imgs/13_3.PNG" width="50%" />
</p>

- Segment map resides in processor
  - Segment number mapped into base/limit pair
  - Base added to offset to generate physical address
  - Error check catches offset out of range
- As many chunks of physical memory as entries
  - Segment addressed by portion of virtual address
  - However, could be included in instruction instead:
    - x86 Example: mov [es:bx],ax.
- What is “V/N” (valid / not valid)?
  - Can mark segments as invalid; requires check as well

\* **OBSERVATIONS**

- Translation on every instruction fetch, load or store
- Virtual address space has holes
  - Segmentation efficient for sparse address spaces
- When it is OK to address outside valid range?
  - This is how the stack (and heap?) allowed to grow
  - For instance, stack takes fault, system automatically increases size of stack
- Need protection mode in segment table
  - For example, code segment would be read-only
  - Data and stack would be read-write (stores allowed)
- What must be saved/restored on context switch?
  - Segment table stored in CPU, not in memory (small)
  - Might store all of processes memory onto disk when switched (called “**swapping**”)

<p align="center">
    <img src="imgs/13_4.PNG" width="40%" />
</p>

\* **PROBLEMS**

- Must fit variable-sized chunks into physical memory
- May move processes multiple times to fit everything
- Limited options for swapping to disk
- **Fragmentation**: wasted space
  - External: free gaps between allocated chunks
  - Internal: don’t need all memory within allocated chunks
  - Solution => Allocate physical memory in fixed size chunks (“pages”)

### 1.2.4. Paging (Fixed sized B&B)

<p align="center">
    <img src="imgs/13_5.PNG" width="50%" />
</p>

- Page Table (One per process)
  - **Resides in physical memory**
  - Contains physical page and permission for each virtual page (e.g. Valid bits, Read, Write, etc)
- Virtual address mapping
  - Offset from Virtual address copied to Physical Address
    - Example: 10 bit offset => 1024-byte pages
  - Virtual page # is all remaining bits
    - Example for 32-bits: 32-10 = 22 bits, i.e. 4 million entries
    - Physical page # copied from table into physical address
  - Check Page Table bounds and permissions

<p align="center">
    <img src="imgs/13_6.PNG" width="50%" />
</p>

\* **Page sharing?**

<p align="center">
    <img src="imgs/13_7.PNG" width="50%" />
</p>

Use cases:
- The “kernel region” of every process has the same page table entries
  - The process cannot access it at user level
  - But on U->K switch, kernel code can access it AS WELL AS the region for THIS user
    - What does the kernel need to do to access other user processes?
- Different processes running same binary!
  - Execute-only, but do not need to duplicate code segments
- User-level system libraries (execute only)
- Shared-memory segments between different processes
  - Can actually share objects directly between processes
    - Must map page into same place in address space!
- This is a limited form of the sharing that threads have within a single process

\* **OBSERVATION**

- What needs to be switched on a context switch?
  - Page table pointer and limit
- What provides protection here?
  - Translation (per process) and dual-mode!
  - Can't let process alter its own page table!

\* **PROBLEMS**

- Pros
  - Simple memory allocation
  - Easy to share
- Con: What if address space is sparse?
  - E.g., on UNIX, code starts at 0, stack starts at (2^31-1)
- Con: What if table really big?
  - Not all pages used all the time => would be nice to have working set of page table in memory
  - With 4KB(typical) page size, 2^(32-12) x 4bytes each = 2^20 x 4bytes each = 4MB. (for x64, 36 exa bytes)

## 1.3. Multi Level Translation

### 1.3.1. Multi Level Paging

<p align="center">
    <img src="imgs/14_1.PNG" width="50%" />
</p>

If page fault for page table arise, it's slow, but by using cache, it's no big deal.

---
\* **What's PTE anyways?**

- What is in a Page Table Entry (or PTE)
  - Pointer to next-level page table or to actual page
  - Permission bits: valid, read-only, read-write, write-only
- Example: Intel x86 architecture PTE:
  - Address same format previous slide (10, 10, 12-bit offset)
  - Intermediate page tables called “Directories”

<p align="center">
    <img src="imgs/14_2.PNG" width="40%" />
</p>

- P: Present (same as “valid” bit in other architectures)
- W: Writeable
- U: User accessible
- PWT: Page write transparent: external cache write-through
- PCD: Page cache disabled (page cannot be cached)
- A: Accessed: page has been accessed recently
- D: Dirty (PTE only): page has been modified recently
- PS: Page Size: PS=1=>4MB page (directory only). Bottom 22 bits of virtual address serve as offset
---
- How do we use the PTE?
  - Invalid PTE can imply different things:
    - Region of address space is actually invalid or
    - Page/directory is just somewhere else than memory
  - Validity checked first
    - OS can use other (say) 31 bits for location info
- Usage Example: **Demand Paging**
  - Keep only active pages in memory
  - Place others on disk and mark their PTEs invalid
- Usage Example: **Copy on Write**
  - UNIX fork gives copy of parent address space to child
    - Address spaces disconnected after child created
  - How to do this cheaply?
    - Make copy of parent's page tables (point at same memory)
    - Mark entries in both sets of page tables as read-only
    - Page fault on write creates two copies
- Usage Example: **Zero Fill On Demand**
  - New data pages must carry no information (say be zeroed)
  - Mark PTEs as invalid; page fault on use gets zeroed page
  - Often, OS creates zeroed pages in background

### 1.3.2. Segments + Pages

Use lowest level to page table, and higher levels to segment table.

<p align="center">
    <img src="imgs/14_3.PNG" width="50%" />
</p>

- Pros:
  - Only need to allocate as many page table entries as we need for application
    - In other wards, sparse address spaces are easy
  - Easy memory allocation
  - Easy Sharing
    - Share at segment or page level (need additional reference counting)
- Cons:
  - One pointer per page (typically 4K - 16K pages today)
  - Page tables need to be contiguous
    - However, the 10b-10b-12b configuration keeps tables to exactly one page in size
  - Two (or more, if >2 levels) lookups per reference
    - Seems very expensive!

\* **We don't use this in modern system.**

- **Paging is sufficient** for memory translation: Modern systems rely heavily on paging for virtual memory management. Paging divides memory into fixed-size pages and uses page tables to translate virtual addresses to physical addresses. This approach provides fine-grained control over memory access, isolation between processes, and efficient use of physical memory.
- Segmentation adds complexity: Using both segmentation and paging together would introduce additional levels of complexity in address translation, which is unnecessary given that paging alone meets the needs of modern systems.

<p align="center">
    <img src="imgs/14_4.PNG" width="40%" />
</p>

### 1.3.3. Inverted Page Table

For just tree-structured forward page tables..
- Size of page table is at least as large as amount of virtual memory allocated to processes
- Physical memory may be much less
  - Much of process space may be out on disk or not in use

So we can use hash table. Size is independent of virtual address space.

<p align="center">
    <img src="imgs/14_5.PNG" width="40%" />
</p>

- Cons:
  - Complexity of managing hash chains: Often in hardware!
  - Poor cache locality of page table

## 1.4. TLB

We record recent 'Virtual Page # to Physical Frame # translation' to TLB. If present, have the physical address without reading any of the page tables, which is really fast.
Even if the translation involved multiple levels, this caches the 'end-to-end result'. But we need to make sure about consistency.
On a TLB miss, the page tables may be cached, so only go to memory when both miss.

